<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <style>
    /* Custom styles for the project */
body {
  font-family: Arial, sans-serif;
}

.container {
  max-width: 960px;
  margin: 0 auto;
  padding: 40px 20px;
}

.university-header {
  background-color: #5c0000;
  color: #ffffff;
  text-align: center;
  padding: 20px 0;
}

.university-header__title {
  font-size: 28px;
  margin: 0;
}

.university-header__description {
  font-size: 18px;
  margin-top: 10px;
}

.university-section {
  padding: 40px 0;
}

.university-section__title {
  font-size: 24px;
  margin-bottom: 20px;
}

.bg-light {
  background-color: #f7f7f7;
}

.row {
  display: flex;
  flex-wrap: wrap;
  margin-right: -15px;
  margin-left: -15px;
}

.col-2 {
  width: calc(16.6667% - 30px);
  margin-right: 15px;
  margin-left: 15px;
}

.col-12 {
  width: 100%;
  margin-right: 0;
  margin-left: 0;
}

.img-fluid {
  max-width: 100%;
  height: auto;
}

.university-footer {
  background-color: #5c0000;
  color: #ffffff;
  text-align: center;
  padding: 20px 0;
}

  </style>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CycleGAN Coloring Book Generator</title>
  <style>
    /* Custom styles for the project */
    /* Add your custom CSS here */
  </style>
</head>

<body>

  <header class="university-header">
    <div class="container">
      <h1 class="university-header__title">CycleGAN Coloring Book Generator</h1>
      <p class="university-header__description">Transform normal photos into coloring book versions using CycleGAN</p>
    </div>
  </header>

  <section class="university-section">
    <div class="container">
      <h2 class="university-section__title">Description</h2>
      <p>
        The CycleGAN Coloring Book Generator is a project that employs the CycleGAN architecture to transform normal photos into coloring book versions. By leveraging the power of CycleGAN, the project enables the conversion of images from one domain to another without the need for paired training data. The generator network learns to map images from the source domain to the target domain, while the discriminator network ensures the realism of the generated coloring book images. This project provides a user-friendly interface to facilitate the seamless generation of coloring book versions from user-supplied photographs.
      </p>
    </div>
  </section>

  <section class="university-section bg-light">
    <div class="container">
      <h2 class="university-section__title">Motivation</h2>
      <p>
        The coloring book generator serves as an offline stress reduction alternative, providing individuals with a creative outlet to unwind and relax. Engaging in coloring activities has been shown to have therapeutic benefits, allowing individuals to escape from everyday stressors and focus their attention on a calming and enjoyable task. By using the coloring book generator, users can easily transform normal photos into coloring book versions, which encourages artistic expression and helps improve fine motor skills. This process can be seen as a hobby, allowing individuals to engage in a pleasurable and rewarding activity during their leisure time. One of the notable advantages of using the coloring book generator is the sense of achievement it brings. As users witness the transformation of their favorite photos into coloring book pages, they experience a sense of accomplishment and satisfaction. This feeling of achievement can boost self-confidence and provide a positive emotional experience. Overall, the coloring book generator serves as an enjoyable and fulfilling activity that promotes stress reduction, encourages artistic expression, improves motor skills, and provides a sense of achievement. By engaging in this offline hobby, individuals can enhance their well-being and find a creative outlet for relaxation and self-expression.
      </p>
    </div>
  </section>

  <section class="university-section">
    <div class="container">
      <h2 class="university-section__title">Technologies</h2>
      <ul>
        <li>Python: Programming language used for development.</li>
        <li>PyTorch: Deep learning framework for training and implementing the CycleGAN model.</li>
        <li>OpenCV: Library for image processing and manipulation.</li>
        <li>GUI Framework (e.g., Tkinter): Used for creating the user interface.</li>
      </ul>
    </div>
  </section>

  <section class="university-section bg-light">
    <div class="container">
      <h2 class="university-section__title">Dataset</h2>
      <p>
        The dataset used in this project consists of two domains: Domain X and Domain Y.

        <li>Domain X:
          Domain X comprises real-world photos sourced from the Open Images dataset. 
          Open Images is a large-scale dataset containing millions of images from diverse categories. The real-world photos in Domain X capture a wide range of subjects, scenes, and objects, providing a rich and varied source of visual data.
          </li>
                <div class="col-2">
          <p>Second Try: Domain X: 100 images Domain Y: 100</p>
          <img src="images/opi.png" alt="2nd Try" title="2nd Try">
        </div>
<li>Domain Y:
Domain Y consists of sketches collected from museums around the world, specifically from the Imagenet-Sketch dataset. Imagenet-Sketch is a curated collection of hand-drawn sketches that represent different objects, animals, and scenes. These sketches have been created by artists and serve as a valuable resource for generating coloring book line drawings.
</li>
                    <div class="col-2">
          <p>Second Try: Domain X: 100 images Domain Y: 100</p>
          <img src="images/imsk.png" alt="2nd Try" title="2nd Try">
        </div>
                    <div class="col-2">
          <p>Second Try: Domain X: 100 images Domain Y: 100</p>
          <img src="images/custom.png" alt="2nd Try" title="2nd Try">
        </div>
By using these two distinct domains, the project aims to leverage the diversity and characteristics of both real-world photos and hand-drawn sketches to train the CycleGAN model. This unpaired dataset allows the model to learn the mapping between the two domains and generate coloring book versions of real-world photos without the need for directly paired training examples.
      </p>
    </div>
  </section>

  <section class="university-section">
    <div class="container">
      <h2 class="university-section__title">Results</h2>
      <div class="row">
        <div class="col-2">
          <p>Input 256x256 pixels</p>
          <img src="images/input.png" alt="Input" title="Input">
        </div>
        <div class="col-2">
          <p>First Try:50 images </p>
          <img src="images/1t.png" alt="1st Try" title="1st Try">
        </div>
        <div class="col-2">
          <p>Second Try: 100 images</p>
          <img src="images/2t.png" alt="2nd Try" title="2nd Try">
        </div>
        <div class="col-2">
          <p>Third Try:  200 images</p>
          <img src="images/3t.png" alt="3rd Try" title="3rd Try">
        </div>
        <div class="col-2">
          <p>Fourth Try: 500 images</p>
          <img src="images/4t.png" alt="4th Try" title="4th Try">
        </div>
      </div>
      <div class="row mt-4">
        <div class="col-12">
          <p>Final Try: 900 images</p>
          <img src="images/5t.png" alt="Actual Results" title="Actual Results" class="img-fluid">
        </div>
      </div>
    </div>
  </section>

  <footer class="university-footer">
    <div class="container">
      <p>&copy; 2023 Your Name. All rights reserved.</p>
    </div>
  </footer>

</body>

</html>
